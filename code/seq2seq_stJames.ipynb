{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A sequence to sequence prediction for YAB and St James' Contact data\n",
    "\n",
    "### MFK, AMW, MLG"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll define a function to preprocess the data and create training and test datasets:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The build_and_train_model function takes as input the training and test data, a mapping from surfaces to integers, the sequence length, and the number of epochs to train the model for. It builds a model with an embedding layer, an LSTM layer, and a dense layer, compiles the model using the categorical crossentropy loss function and the Adam optimizer, and trains the model on the training data for the specified number of epochs. It returns the trained model and the surface-to-integer mapping.\n",
    "- The preprocess_data function takes as input the data and the sequence length. It creates a mapping from surfaces to integers, converts the data to integers using the surface-to-integer mapping, splits the data into input sequences and labels, one-hot encodes the labels, pads the input sequences with padding tokens to ensure that they all have the same length, and splits the padded sequences and labels into training and test sets. It returns the training and test data and labels, as well as the surface-to-integer mapping.\n",
    "- The toy dataset is a list of three sequences of surface contacts.\n",
    "- The preprocess_data function is called to preprocess the toy dataset, using a sequence length of 11.\n",
    "- The build_and_train_model function is called to build and train a model on the preprocessed data, using a sequence length of 11 and the default number of epochs (100).\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "def preprocess_data(data, sequence_length):\n",
    "    # Flatten the list of sequences into a single string\n",
    "    data = ''.join(data)\n",
    "    \n",
    "    # Create a mapping from surfaces to integers\n",
    "    surfaces = sorted(set(data))\n",
    "    surface_to_int = dict((c, i) for i, c in enumerate(surfaces))\n",
    "    \n",
    "    # Convert the data to integers using the surface-to-integer mapping\n",
    "    data_int = [surface_to_int[c] for c in data]\n",
    "    \n",
    "    # Split the data into input sequences and labels\n",
    "    inputs = []\n",
    "    labels = []\n",
    "    for i in range(0, len(data_int) - sequence_length, 1):\n",
    "        inputs.append(data_int[i:i + sequence_length])\n",
    "        labels.append(data_int[i + sequence_length])\n",
    "        \n",
    "    # One-hot encode the labels\n",
    "    labels = tensorflow.keras.utils.to_categorical(labels)\n",
    "    \n",
    "    # Pad the input sequences with zeros to make them all the same length\n",
    "    inputs = tensorflow.keras.preprocessing.sequence.pad_sequences(inputs, maxlen=sequence_length, padding='pre', value=0)\n",
    "    \n",
    "    # Split the data into training and testing sets\n",
    "    x_train, x_test, y_train, y_test = train_test_split(inputs, labels, test_size=0.2, random_state=42)\n",
    "    \n",
    "    return x_train, x_test, y_train, y_test, surface_to_int\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can define a function to build and train the RNN model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tensorflow\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "def build_and_train_model(x_train, y_train, x_test, y_test, surface_to_int, sequence_length, epochs=100):\n",
    "    # Build the model\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(input_dim=len(surface_to_int), output_dim=10, input_length=sequence_length))\n",
    "    model.add(LSTM(units=50))\n",
    "    model.add(Dense(units=y_train.shape[1], activation='softmax'))\n",
    "\n",
    "    tensorflow.config.run_functions_eagerly(True)\n",
    "    \n",
    "    # Compile the model\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'],run_eagerly=True)\n",
    "    \n",
    "    # Train the model\n",
    "    model.fit(x_train, y_train, epochs=epochs, validation_data=(x_test, y_test))\n",
    "    \n",
    "    return model, surface_to_int\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can put everything together and use the model to make predictions on a new sequence of surface contacts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Toy dataset of surface contacts\n",
    "data = ['ABGFGE', 'GBESGSGS', 'EEGEGEGEBAE']\n",
    "\n",
    "# Preprocess the data\n",
    "x_train, x_test, y_train, y_test, surface_to_int = preprocess_data(data, sequence_length=11)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[4, 5, 2, 2, 4, 2, 4, 2, 4, 2, 1],\n",
       "        [2, 4, 1, 2, 5, 4, 5, 4, 5, 2, 2],\n",
       "        [2, 5, 4, 5, 4, 5, 2, 2, 4, 2, 4],\n",
       "        [4, 3, 4, 2, 4, 1, 2, 5, 4, 5, 4],\n",
       "        [1, 4, 3, 4, 2, 4, 1, 2, 5, 4, 5],\n",
       "        [5, 2, 2, 4, 2, 4, 2, 4, 2, 1, 0],\n",
       "        [4, 2, 4, 1, 2, 5, 4, 5, 4, 5, 2],\n",
       "        [1, 2, 5, 4, 5, 4, 5, 2, 2, 4, 2],\n",
       "        [4, 5, 4, 5, 2, 2, 4, 2, 4, 2, 4],\n",
       "        [3, 4, 2, 4, 1, 2, 5, 4, 5, 4, 5],\n",
       "        [4, 1, 2, 5, 4, 5, 4, 5, 2, 2, 4]], dtype=int32),\n",
       " array([[5, 4, 5, 4, 5, 2, 2, 4, 2, 4, 2],\n",
       "        [5, 4, 5, 2, 2, 4, 2, 4, 2, 4, 2],\n",
       "        [0, 1, 4, 3, 4, 2, 4, 1, 2, 5, 4]], dtype=int32),\n",
       " array([[1., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0., 0., 0.],\n",
       "        [0., 0., 1., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0., 0., 0.],\n",
       "        [0., 0., 1., 0., 0., 0.],\n",
       "        [0., 0., 1., 0., 0., 0.]], dtype=float32),\n",
       " array([[0., 0., 0., 0., 1., 0.],\n",
       "        [0., 1., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 1.]], dtype=float32),\n",
       " {'A': 0, 'B': 1, 'E': 2, 'F': 3, 'G': 4, 'S': 5})"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test, surface_to_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.python/current/lib/python3.10/site-packages/tensorflow/python/data/ops/structured_function.py:256: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step - loss: 1.7955 - accuracy: 0.0000e+00 - val_loss: 1.7902 - val_accuracy: 0.3333\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 1.7898 - accuracy: 0.0000e+00 - val_loss: 1.7921 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 1.7842 - accuracy: 0.5455 - val_loss: 1.7941 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 139ms/step - loss: 1.7785 - accuracy: 0.5455 - val_loss: 1.7960 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 1.7728 - accuracy: 0.5455 - val_loss: 1.7979 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 1.7669 - accuracy: 0.5455 - val_loss: 1.7999 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 1.7608 - accuracy: 0.5455 - val_loss: 1.8020 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 137ms/step - loss: 1.7545 - accuracy: 0.5455 - val_loss: 1.8041 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 1.7478 - accuracy: 0.5455 - val_loss: 1.8065 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 142ms/step - loss: 1.7407 - accuracy: 0.5455 - val_loss: 1.8090 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 138ms/step - loss: 1.7330 - accuracy: 0.5455 - val_loss: 1.8118 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 1.7247 - accuracy: 0.5455 - val_loss: 1.8148 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 1.7157 - accuracy: 0.5455 - val_loss: 1.8182 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 1.7057 - accuracy: 0.5455 - val_loss: 1.8220 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 1.6948 - accuracy: 0.5455 - val_loss: 1.8264 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 1.6827 - accuracy: 0.5455 - val_loss: 1.8314 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 1.6692 - accuracy: 0.5455 - val_loss: 1.8374 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 1.6542 - accuracy: 0.5455 - val_loss: 1.8445 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 1.6373 - accuracy: 0.5455 - val_loss: 1.8531 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 1.6184 - accuracy: 0.5455 - val_loss: 1.8637 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 1.5971 - accuracy: 0.5455 - val_loss: 1.8769 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 1.5731 - accuracy: 0.5455 - val_loss: 1.8935 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 137ms/step - loss: 1.5462 - accuracy: 0.5455 - val_loss: 1.9149 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 1.5161 - accuracy: 0.5455 - val_loss: 1.9427 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 1.4827 - accuracy: 0.5455 - val_loss: 1.9796 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 1.4461 - accuracy: 0.5455 - val_loss: 2.0290 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 144ms/step - loss: 1.4070 - accuracy: 0.5455 - val_loss: 2.0960 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 1.3668 - accuracy: 0.5455 - val_loss: 2.1874 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 1.3281 - accuracy: 0.5455 - val_loss: 2.3108 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 1.2949 - accuracy: 0.5455 - val_loss: 2.4716 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 1.2719 - accuracy: 0.5455 - val_loss: 2.6656 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 1.2627 - accuracy: 0.5455 - val_loss: 2.8700 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 136ms/step - loss: 1.2665 - accuracy: 0.5455 - val_loss: 3.0462 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 1.2762 - accuracy: 0.5455 - val_loss: 3.1625 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 1.2830 - accuracy: 0.5455 - val_loss: 3.2097 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 1.2818 - accuracy: 0.5455 - val_loss: 3.1961 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 1.2722 - accuracy: 0.5455 - val_loss: 3.1367 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 1.2568 - accuracy: 0.5455 - val_loss: 3.0477 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 1.2390 - accuracy: 0.5455 - val_loss: 2.9439 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 1.2220 - accuracy: 0.5455 - val_loss: 2.8378 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 1.2080 - accuracy: 0.5455 - val_loss: 2.7389 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 1.1981 - accuracy: 0.5455 - val_loss: 2.6532 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 1.1920 - accuracy: 0.5455 - val_loss: 2.5838 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 134ms/step - loss: 1.1888 - accuracy: 0.5455 - val_loss: 2.5315 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 1.1871 - accuracy: 0.5455 - val_loss: 2.4959 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 1.1857 - accuracy: 0.5455 - val_loss: 2.4759 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 1.1837 - accuracy: 0.5455 - val_loss: 2.4703 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 136ms/step - loss: 1.1806 - accuracy: 0.5455 - val_loss: 2.4781 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 1.1762 - accuracy: 0.5455 - val_loss: 2.4984 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 1.1708 - accuracy: 0.5455 - val_loss: 2.5303 - val_accuracy: 0.0000e+00\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 1.1646 - accuracy: 0.5455 - val_loss: 2.5728 - val_accuracy: 0.0000e+00\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 1.1582 - accuracy: 0.5455 - val_loss: 2.6243 - val_accuracy: 0.0000e+00\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 1.1521 - accuracy: 0.5455 - val_loss: 2.6828 - val_accuracy: 0.0000e+00\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 141ms/step - loss: 1.1467 - accuracy: 0.5455 - val_loss: 2.7455 - val_accuracy: 0.0000e+00\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 1.1423 - accuracy: 0.5455 - val_loss: 2.8091 - val_accuracy: 0.0000e+00\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 1.1388 - accuracy: 0.5455 - val_loss: 2.8696 - val_accuracy: 0.0000e+00\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 1.1362 - accuracy: 0.5455 - val_loss: 2.9235 - val_accuracy: 0.0000e+00\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 1.1340 - accuracy: 0.5455 - val_loss: 2.9680 - val_accuracy: 0.0000e+00\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 1.1318 - accuracy: 0.5455 - val_loss: 3.0013 - val_accuracy: 0.0000e+00\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 1.1295 - accuracy: 0.5455 - val_loss: 3.0231 - val_accuracy: 0.0000e+00\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 1.1268 - accuracy: 0.5455 - val_loss: 3.0344 - val_accuracy: 0.0000e+00\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 1.1240 - accuracy: 0.5455 - val_loss: 3.0371 - val_accuracy: 0.0000e+00\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 1.1210 - accuracy: 0.5455 - val_loss: 3.0337 - val_accuracy: 0.0000e+00\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 1.1181 - accuracy: 0.5455 - val_loss: 3.0269 - val_accuracy: 0.0000e+00\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 1.1155 - accuracy: 0.5455 - val_loss: 3.0193 - val_accuracy: 0.0000e+00\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 1.1130 - accuracy: 0.5455 - val_loss: 3.0132 - val_accuracy: 0.0000e+00\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 1.1109 - accuracy: 0.5455 - val_loss: 3.0105 - val_accuracy: 0.0000e+00\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 1.1089 - accuracy: 0.5455 - val_loss: 3.0127 - val_accuracy: 0.0000e+00\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 1.1071 - accuracy: 0.5455 - val_loss: 3.0205 - val_accuracy: 0.0000e+00\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 140ms/step - loss: 1.1053 - accuracy: 0.5455 - val_loss: 3.0343 - val_accuracy: 0.0000e+00\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 1.1036 - accuracy: 0.5455 - val_loss: 3.0540 - val_accuracy: 0.0000e+00\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 1.1019 - accuracy: 0.5455 - val_loss: 3.0787 - val_accuracy: 0.0000e+00\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 1.1003 - accuracy: 0.5455 - val_loss: 3.1074 - val_accuracy: 0.0000e+00\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 1.0985 - accuracy: 0.5455 - val_loss: 3.1387 - val_accuracy: 0.0000e+00\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 1.0968 - accuracy: 0.5455 - val_loss: 3.1710 - val_accuracy: 0.0000e+00\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 1.0949 - accuracy: 0.5455 - val_loss: 3.2030 - val_accuracy: 0.0000e+00\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 141ms/step - loss: 1.0930 - accuracy: 0.5455 - val_loss: 3.2335 - val_accuracy: 0.0000e+00\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 1.0910 - accuracy: 0.5455 - val_loss: 3.2614 - val_accuracy: 0.0000e+00\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 1.0889 - accuracy: 0.5455 - val_loss: 3.2865 - val_accuracy: 0.0000e+00\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 1.0869 - accuracy: 0.5455 - val_loss: 3.3084 - val_accuracy: 0.0000e+00\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 1.0848 - accuracy: 0.5455 - val_loss: 3.3275 - val_accuracy: 0.0000e+00\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 1.0828 - accuracy: 0.5455 - val_loss: 3.3442 - val_accuracy: 0.0000e+00\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 1.0807 - accuracy: 0.5455 - val_loss: 3.3591 - val_accuracy: 0.0000e+00\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 1.0785 - accuracy: 0.5455 - val_loss: 3.3727 - val_accuracy: 0.0000e+00\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 1.0762 - accuracy: 0.5455 - val_loss: 3.3856 - val_accuracy: 0.0000e+00\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 1.0738 - accuracy: 0.5455 - val_loss: 3.3979 - val_accuracy: 0.0000e+00\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 133ms/step - loss: 1.0712 - accuracy: 0.5455 - val_loss: 3.4100 - val_accuracy: 0.0000e+00\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 1.0685 - accuracy: 0.5455 - val_loss: 3.4217 - val_accuracy: 0.0000e+00\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 1.0658 - accuracy: 0.5455 - val_loss: 3.4331 - val_accuracy: 0.0000e+00\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 1.0630 - accuracy: 0.5455 - val_loss: 3.4440 - val_accuracy: 0.0000e+00\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 1.0601 - accuracy: 0.5455 - val_loss: 3.4545 - val_accuracy: 0.0000e+00\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 1.0572 - accuracy: 0.5455 - val_loss: 3.4649 - val_accuracy: 0.0000e+00\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 1.0541 - accuracy: 0.5455 - val_loss: 3.4755 - val_accuracy: 0.0000e+00\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 1.0510 - accuracy: 0.5455 - val_loss: 3.4870 - val_accuracy: 0.0000e+00\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 1.0477 - accuracy: 0.5455 - val_loss: 3.5000 - val_accuracy: 0.0000e+00\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 1.0444 - accuracy: 0.5455 - val_loss: 3.5151 - val_accuracy: 0.0000e+00\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 1.0409 - accuracy: 0.5455 - val_loss: 3.5328 - val_accuracy: 0.0000e+00\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 1.0374 - accuracy: 0.5455 - val_loss: 3.5531 - val_accuracy: 0.0000e+00\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 1.0338 - accuracy: 0.5455 - val_loss: 3.5756 - val_accuracy: 0.0000e+00\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 161ms/step - loss: 1.0302 - accuracy: 0.5455 - val_loss: 3.5996 - val_accuracy: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "# Build and train the model\n",
    "model, surface_to_int = build_and_train_model(x_train, y_train, x_test, y_test, surface_to_int, sequence_length=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 76ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.python/current/lib/python3.10/site-packages/tensorflow/python/data/ops/structured_function.py:256: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n"
     ]
    }
   ],
   "source": [
    "start_surface = 'A'\n",
    "\n",
    "# Initialize the input sequence with a single surface contact\n",
    "input_sequence = np.array([[surface_to_int[start_surface]]])\n",
    "\n",
    "# Initialize an empty list to store the predicted surface contacts\n",
    "predicted_surfaces = []\n",
    "\n",
    "# Set the number of surface contacts to predict\n",
    "num_predictions = 10\n",
    "\n",
    "# Iterate over the number of predictions\n",
    "for i in range(num_predictions):\n",
    "    # Use the model to predict the next surface contact\n",
    "    prediction = model.predict(input_sequence)[0]\n",
    "    \n",
    "    # Convert the one-hot encoded prediction back to an integer\n",
    "    prediction = np.argmax(prediction)\n",
    "    \n",
    "    # Append the prediction to the list of predicted surfaces\n",
    "    predicted_surfaces.append(prediction)\n",
    "    \n",
    "    # Update the input sequence with the prediction\n",
    "    input_sequence = np.array([[prediction]])\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3ad933181bd8a04b432d3370b9dc3b0662ad032c4dfaa4e4f1596c548f763858"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
